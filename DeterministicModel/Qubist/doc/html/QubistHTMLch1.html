<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>1 Global Optimization with Qubist</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,frames,3 --> 
<meta name="src" content="QubistHTML.tex"> 
<meta name="date" content="2012-02-01 01:22:00"> 
<link rel="stylesheet" type="text/css" href="QubistHTML.css"> 
</head><body 
>
<!--l. 216--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLch2.html" >next</a>] [<a 
href="#tailQubistHTMLch1.html">tail</a>] [<a 
href="QubistHTML3.html#QubistHTMLch1.html" >up</a>] </p></div>
<h2 class="chapterHead"><span class="titlemark">Chapter&#x00A0;1</span><br /><a 
 id="x4-10001"></a>Global Optimization with Qubist</h2>
<a 
 id="dx4-1001"></a>
     <div class="quote">
     <!--l. 225--><p class="noindent" ><span 
class="cmti-10">nQube&#8217;s</span>
     <span 
class="cmti-10">goal</span>
     <span 
class="cmti-10">is</span>
     <span 
class="cmti-10">to</span>
     <span 
class="cmti-10">remove</span>
     <span 
class="cmti-10">the</span>
     <span 
class="cmti-10">technical</span>
     <span 
class="cmti-10">burdens</span>
     <span 
class="cmti-10">of</span>
     <span 
class="cmti-10">tough</span>
     <span 
class="cmti-10">optimization</span>
     <span 
class="cmti-10">and</span>
     <span 
class="cmti-10">data-modeling</span>
     <span 
class="cmti-10">problems</span>
     <span 
class="cmti-10">as</span>
     <span 
class="cmti-10">much</span>
     <span 
class="cmti-10">as</span>
     <span 
class="cmti-10">possible,</span>
     <span 
class="cmti-10">so</span>
     <span 
class="cmti-10">that</span>
     <span 
class="cmti-10">you</span>
     <span 
class="cmti-10">can</span>
     <span 
class="cmti-10">focus</span>
     <span 
class="cmti-10">on</span>
     <span 
class="cmti-10">your</span>
     <span 
class="cmti-10">particular</span>
     <span 
class="cmti-10">applications.</span></div>
<a 
 id="dx4-1002"></a>
<a 
 id="dx4-1003"></a>
<!--l. 231--><p class="noindent" >Many problems in science and engineering can be reduced to the global optimization of parametric models or
simulated systems, subject to some user-defined objective, or possibly multiple objectives. The simplest
and possibly most common example is the problem of curve-fitting or data-modeling, which requires
the minimization of a <span 
class="cmmi-10">&#x03C7;</span><sup><span 
class="cmr-7">2</span></sup> function that determines the deviation from a perfect fit. Other examples
common to engineering involve the optimization of a design, subject to one or several criteria. For
simple problems with few parameters, the optimization procedure is simple and virtually any local
                                                                                         

                                                                                         
optimization technique will work. However, things become more difficult when the number of parameters is
large, noise is present, or multiple local optima exist in the parameter space. In such cases, simple
optimization techniques will usually <span 
class="cmti-10">fail </span>and one must resort to more sophisticated global optimization
techniques.
<a 
 id="dx4-1004"></a>
<a 
 id="dx4-1005"></a>
<!--l. 235--><p class="noindent" >Global optimization is the process of finding the &#8216;best&#8217; feasible solution or family of solutions to a given problem
that exists within the problem&#8217;s parameter space, subject to one or more objectives and all applicable constraints. In
general, this is a much harder problem than local optimization, which follows the topography of a function
and ascends to the top of the first peak encountered, or descends to the bottom of the nearest valley
(depending on whether the problem is one of maximization or minimization), without worrying about the
possible existence of better solutions elsewhere in the parameter space. Global optimizers are designed to
search a problem&#8217;s parameter space thoroughly and provide some degree of confidence that a solution is
globally optimal. Even so, it is seldom possible to guarantee mathematically that absolutely the best
solution has been discovered, since this would require an exhaustive search of the entire parameter
space, which is not practical unless the problem has very few parameters. There are no known global
optimization procedures that are guaranteed to work on all problems, except for exhaustive search, and the
greatest challenge of this field is to develop algorithms that are effective and efficient on a wide range of
problems.
<a 
 id="dx4-1006"></a>
<a 
 id="dx4-1007"></a>
<a 
 id="dx4-1008"></a>
<a 
 id="dx4-1009"></a>
<!--l. 241--><p class="noindent" >Qubist is third-party MATLAB toolbox for global optimization, data-modeling, and visualization that is written by
myself and distributed by nQube Technical Computing Corporation. MATLAB 7.0 or higher is required, and the
package works with Windows, MacIntosh (OS X and Power PC), and Linux. No additional MATLAB toolboxes are
required.
<!--l. 243--><p class="noindent" >The Qubist platform offers five complementary optimization algorithms
     <ul class="itemize1">
     <li class="itemize">
     Ferret:
     a
     parallel
     multi-objective
     genetic
     algorithm
     with
     sophisticated
     machine-learning
     features
     </li>
     <li class="itemize">
     Locust:
                                                                                         

                                                                                         
     a
     parallel
     multi-objective
     particle
     swarm
     algorithm
     </li>
     <li class="itemize">
     SAMOSA:
     a
     &#8216;Simple
     Approach
     to
     a
     Multi-Objective
     Simplex
     Algorithm&#8217;
     </li>
     <li class="itemize">
     Anvil:
     an
     innovative
     simulated
     anneal/genetic
     algorithm
     hybrid
     code
     </li>
     <li class="itemize">
     SemiGloSS:
     a
     unique
     experimental
     &#8216;<span class="underline">Semi</span>-<span class="underline">Glo</span>bal
     <span class="underline">S</span>olution
     <span class="underline">S</span>pray&#8217;
     algorithm.</li></ul>
<a 
 id="dx4-1010"></a>
<!--l. 253--><p class="noindent" >All Qubist optimizers are interchangeable and the package contains several other tools to assist with
the analysis of runs and the visualization of multi-dimensional solution sets. Ferret and Locust are
considered to be the &#8216;front line&#8217; optimizers most suitable for very large or difficult problems. SAMOSA
and Anvil are secondary optimizers that are less powerful than Ferret and Locust. SemiGloSS is an
                                                                                         

                                                                                         
experimental optimizer that shows some promise, but is not ready for serious use. All of the Qubist
optimizers, except for SemiGloSS, are discussed in this guide, as well as supporting tools for analysis and
visualization.
<div class="subsectionTOCS">
&#x00A0;&#x00A0;<span class="subsectionToc" >1.0.1 <a 
href="#x4-20001.0.1" id="QQ2-4-2">Qubist&#8217;s &#8216;Front Line&#8217; Optimizers</a></span>
<br />&#x00A0;&#x00A0;<span class="subsectionToc" >1.0.2 <a 
href="#x4-30001.0.2" id="QQ2-4-3">Qubist&#8217;s Secondary Optimizers and Polishers</a></span>
<br />&#x00A0;&#x00A0;<span class="subsectionToc" >1.0.3 <a 
href="#x4-40001.0.3" id="QQ2-4-4">The Big Picture</a></span>
<br />&#x00A0;&#x00A0;<span class="subsectionToc" >1.0.4 <a 
href="#x4-50001.0.4" id="QQ2-4-5">About This User&#8217;s Guide</a></span>
</div>
<h4 class="subsectionHead"><span class="titlemark">1.0.1   </span> <a 
 id="x4-20001.0.1"></a>Qubist&#8217;s &#8216;Front Line&#8217; Optimizers</h4>
<a 
 id="dx4-2001"></a>
<a 
 id="dx4-2002"></a>
<a 
 id="dx4-2003"></a>
<a 
 id="dx4-2004"></a>
<a 
 id="dx4-2005"></a>
<a 
 id="dx4-2006"></a>
<!--l. 265--><p class="noindent" >Ferret is a powerful and flexible multi-objective genetic algorithm with numerous machine-learning enhancements,
techniques borrowed from other evolutionary computing methods, and many unique features. Ferret is designed to
handle extremely difficult optimization problems and is larger than all of the other Qubist optimizers combined.
Locust is a multi-objective particle swarm optimizer that has undergone rapid recent development. It is a much
smaller, &#8216;snappier&#8217; code than Ferret, with fewer options and less computational overhead, but the latest versions
rival Ferret on some problems. Together, Ferret and Locust are the best optimizers of the Qubist
package for difficult problems. Both are designed as parallel algorithms that can take advantage of
multi-CPU machines or clusters <span 
class="cmti-10">without </span>requiring MATLAB&#8217;s parallel computing toolbox or other third
party software, and both both have sophisticated visualization capabilities to help you understand
the parameter space of your problem. It is also noteworthy that both Ferret and Locust can call the
secondary optimizers of the Qubist package (SAMOSA, Anvil, and SemiGloSS), as well as MATLAB&#8217;s
built-in optimizer fminsearch, as polishers to improve the quality of the solution set at the end of a
run.
<a 
 id="dx4-2007"></a>
<a 
 id="dx4-2008"></a>
<a 
 id="dx4-2009"></a>
<!--l. 270--><p class="noindent" >Up until this year, Ferret was <span 
class="cmti-10">by far </span>the most powerful and sophisticated global optimizer in the Qubist package,
and the clear choice for most problems. There were two reasons for this disparity of power. First of all, Ferret has
been under constant development for over seven years at the time of this writing, while the other optimizers are only
one to three years old. Secondly, and more importantly, the paradigm of biological evolution offers a very rich
framework to design an optimizer. The dynamics of evolution is complex and offers more flexibility than the
relatively simple dynamics of a particle swarm, the statistical process of annealing, or the simple rules of a simplex
algorithm. The gap between Ferret and Locust has narrowed very recently - in fact during the writing of this
user&#8217;s guide. As I wrote, I cleaned out some questionable features of Locust that were muddying my
                                                                                         

                                                                                         
understanding of the code, and the result was a new insight that improved the code dramatically. The
new Locust-2 particle swarm optimizer is a very powerful optimizer - still perhaps not as powerful as
Ferret on truly difficult problems, but the difference is much smaller than it was even six months ago. I
expect that future development may narrow this margin even further. Locust has developed much
more rapidly than Ferret, largely because in some way it <span 
class="cmti-10">is </span>Ferret. The swarm equations are unique to
Locust, but many other components have been recycled from its older brother, including parts of
the user interface, built-in visualization and analysis code, and even a large fraction of the internal
logic. Nevertheless, Ferret remains my choice for tough, &#8216;mission-critical&#8217; problems, partly due to its
much longer development and testing history, as well as my own personal bias towards evolutionary
codes.
<!--l. 272--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">1.0.2   </span> <a 
 id="x4-30001.0.2"></a>Qubist&#8217;s Secondary Optimizers and Polishers</h4>
<a 
 id="dx4-3001"></a>
<a 
 id="dx4-3002"></a>
<a 
 id="dx4-3003"></a>
<a 
 id="dx4-3004"></a>
<a 
 id="dx4-3005"></a>
<a 
 id="dx4-3006"></a>
<!--l. 281--><p class="noindent" >Qubist&#8217;s secondary optimizers can be used as as standalone optimizers for easier problems, or &#8216;polishers&#8217; for tough
problems to improve the accuracy of the final solution set. They are also useful for difficult problems when the
emphasis is on obtaining good solution quickly, and not necessarily solutions that are truly optimal in a global sense.
SAMOSA is an acronym for &#8216;Simple Approach to a Multi-Objective Simplex Algorithm&#8217;. It is Qubist&#8217;s
default polisher for multi-objective optimization problems (see Section <a 
href="QubistHTMLse1.html#x7-70002.1">2.1<!--tex4ht:ref: sec:MOO --></a>), and quite a useful tool for
small stand-alone problems. As a simplex algorithm, SAMOSA has much in common with MATLAB&#8217;s
built-in fminsearch optimizer, except that it is designed for multi-objective problems like all Qubist
optimizers, and has a nice graphical interface that you can optionally use for visualization of your
run. SAMOSA is sufficiently lightweight that it can even be called from <span 
class="cmti-10">inside </span>of a Ferret or Locust
fitness function, for sophisticated problems that require an internal optimization step within an outer
optimization handled by Ferret or Locust. Ferret also optionally uses SAMOSA as a local optimizer
while as it runs to provide a local optimization step to speed up the convergence of multi-objective
problems.<span class="footnote-mark"><a 
href="QubistHTML5.html#fn1x1"><sup class="textsuperscript">1</sup></a></span><a 
 id="x4-3007f1"></a> 
<a 
 id="dx4-3008"></a>
<a 
 id="dx4-3009"></a>
<a 
 id="dx4-3010"></a>
<!--l. 286--><p class="noindent" >Anvil is an innovative multi-objective simulated annealing/genetic algorithm hybrid code, whose genetic
algorithm components borrow heavily from Ferret. Anvil is quite a powerful global optimizer in its
own right, although not as powerful or as &#8216;global&#8217; as Ferret and Locust for most problems. It has less
computational overhead than either of the front line optimizers though, and might find a niche for
                                                                                         

                                                                                         
medium-difficulty problems where speed is important. Like SAMOSA, Anvil can be used by both Ferret and
Locust as a very thorough and robust solution polisher at the end of a run. However, it cannot be used
during Ferret&#8217;s local optimization step, where a more lightweight optimizer (SAMOSA or fminsearch) is
required.
<a 
 id="dx4-3011"></a>
<a 
 id="dx4-3012"></a>
<a 
 id="dx4-3013"></a>
<a 
 id="dx4-3014"></a>
<a 
 id="dx4-3015"></a>
<!--l. 293--><p class="noindent" >SemiGloSS&#x00A0;is the &#8216;<span class="underline">Semi</span>-<span class="underline">Glo</span>bal <span class="underline">S</span>olution <span class="underline">S</span>pray&#8217; optimizer, which is an experimental multi-objective optimizer that is
very fast, but not a true global optimizer. SemiGloSS&#x00A0;is not ready ready for research-level problems, but is included
for comparison. It may occasionally be useful as an alternative multi-objective solution polisher, but it probably
should not be used as a standalone optimizer for problems of any importance. I have left SemiGloSS&#x00A0;out of this
user&#8217;s guide because its future is highly uncertain at the time of this writing. Try it if you wish, but its features
will remain undocumented, and subject to major changes, until the code is much further along in
development.
<a 
 id="dx4-3016"></a>
<h4 class="subsectionHead"><span class="titlemark">1.0.3   </span> <a 
 id="x4-40001.0.3"></a>The Big Picture</h4>
<a 
 id="dx4-4001"></a>
<a 
 id="dx4-4002"></a>
<a 
 id="dx4-4003"></a>
<a 
 id="dx4-4004"></a>
<!--l. 305--><p class="noindent" >Qubist&#8217;s design includes seamless integration between its component optimizers, simplicity of use, extreme flexibility,
built-in parallelization, visualization tools, and &#8216;knowledge discovery&#8217; capabilities that go beyond traditional
optimizers. The Qubist package is best regarded as the &#8216;front line&#8217; optimizers Ferret and Locust, plus a collection of
visualization and analysis tools, and lesser optimizers that are suitable or polishing solutions and problems of lesser
difficulty. Because of Ferret&#8217;s dominant role the history of the Qubist project and the package, Qubist as a whole
always carries the same version number as Ferret. Locust has developed rapidly in recent history and I expect that
this trend will continue for the near future, but Ferret still remains the gold standard of the current
release.
<!--l. 307--><p class="noindent" >The combination of Ferret, Locust, SAMOSA, and Anvil effectively covers the spectrum of optimization
requirements for most users, and together represent a formidable and very complete set of optimization tools. An
important strength of the Qubist package is that its components are completely integrated and consistent in their
usage. The optimizers are &#8216;swappable&#8217; in the sense that they all use the same formats for their fitness functions and
understand Ferret&#8217;s setup files. Once a project runs with Ferret, it will work automatically with any of the Qubist
optimizers without even a single modification.
<a 
 id="dx4-4005"></a>
<!--l. 310--><p class="noindent" >nQube&#8217;s goal, and my goal personally, is to remove the technical burdens of tough optimization and data-modeling
problems, as much as possible, so that you can focus on your particular applications. Qubist works toward this
goal by providing advanced tools for global optimization and modeling of real-world problems, which
are embedded in a simple and intuitive user interface designed to simplify the tasks of visualization,
parameter space exploration, analysis, and parallel computing. The features that make this possible
are introduced in Chapter <a 
href="QubistHTMLch2.html#x6-60002">2<!--tex4ht:ref: ch:tour --></a> and discussed in more detail throughout the remainder of this user&#8217;s
                                                                                         

                                                                                         
guide.
<!--l. 312--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">1.0.4   </span> <a 
 id="x4-50001.0.4"></a>About This User&#8217;s Guide</h4>
<a 
 id="dx4-5001"></a>
<a 
 id="dx4-5002"></a>
<!--l. 317--><p class="noindent" >As a final note in this chapter, I would like to point out that this user&#8217;s guide is absolutely not intended as an
academic treatise on GAs, evolutionary computing, or techniques for global optimization. My goal is perhaps less
ambitious - I intend to document the features that I built into Qubist, discuss why things are the way that they are,
and offer advice on how to configure and use this particular software effectively. In the process, I will show you how
to configure Qubist to solve some very difficult optimization and modeling problems, while avoiding the pitfalls that
new users commonly run into. I have written this guide in a very informal style with the hope that it
might capture a wider audience in technical computing circles outside of academia. Certainly, there
are some very advanced techniques &#8216;under the hood&#8217; of Qubist, but fortunately you don&#8217;t have to
understand these techniques in detail to use the software effectively. With optimization problems,
the proof is truly in the pudding - your final result is more important than how you found it, and
furthermore, you can always verify whether your solution is better than one you obtained by other more
conventional means. This guide is also deliberately light on references, which might disappoint some
academics, but this would not be consistent with the conversational style of the text or my stated
goals.
<!--l. 319--><p class="noindent" >For those readers who would like a more formal introduction to genetic algorithms, I heartily recommend the
two books by David Goldberg: &#8216;Genetic Algorithms in Search, Optimization, and Machine Learning&#8217;
[<a 
href="QubistHTMLli1.html#Xgoldberg89">Goldberg</a>,&#x00A0;<a 
href="QubistHTMLli1.html#Xgoldberg89">1989</a>] and &#8216;The Design of Innovation: Lessons From and for Competent Genetic Algorithms.&#8217;
[<a 
href="QubistHTMLli1.html#Xgoldberg02">Goldberg</a>,&#x00A0;<a 
href="QubistHTMLli1.html#Xgoldberg02">2002</a>]. His newer book was particularly influential to me as I developed Ferret&#8217;s linkage-learning
system, which is similar in spirit to the techniques described there, but quite different in operation.
There are also plenty of academic papers on genetic algorithms, particle swarms, simulated annealing,
and other global optimization techniques that can be readily found by searching electronic journals
on the internet. I would encourage you to do so if you are at all interested in optimization as a field
of study. However, if you just want to get down to business and tackle your own optimization and
modeling problems, then this guide will give you sufficient tools and background information to do
so.
<a 
 id="dx4-5003"></a>
                                                                                         

                                                                                         
<!--l. 325--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLch2.html" >next</a>] [<a 
href="QubistHTMLch1.html" >front</a>] [<a 
href="QubistHTML3.html#QubistHTMLch1.html" >up</a>] </p></div>
<!--l. 325--><p class="noindent" ><a 
 id="tailQubistHTMLch1.html"></a>  
</body></html> 
