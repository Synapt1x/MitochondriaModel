<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Introduction and History</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,frames,3 --> 
<meta name="src" content="QubistHTML.tex"> 
<meta name="date" content="2012-02-01 01:22:00"> 
<link rel="stylesheet" type="text/css" href="QubistHTML.css"> 
</head><body 
>
<!--l. 3722--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse38.html" >next</a>] [<a 
href="#tailQubistHTMLse37.html">tail</a>] [<a 
href="QubistHTMLch6.html#QubistHTMLse37.html" >up</a>] </p></div>
<h3 class="sectionHead"><span class="titlemark">6.1   </span> <a 
 id="x57-810006.1"></a>Introduction and History</h3>
<a 
 id="dx57-81001"></a>
<a 
 id="dx57-81002"></a>
<a 
 id="dx57-81003"></a>
<a 
 id="dx57-81004"></a>
<!--l. 3729--><p class="noindent" >Parallel computing with Qubist has had a somewhat convoluted history throughout the development of the code,
which goes back to 2002-2003, when Ferret was the only optimizer in the package. Ferret-1 (circa 2002-2003) was in
fact was a parallel code, which made use of Java RMI (Remote Method Invocation). This was a natural choice
because:
     <ul class="itemize1">
     <li class="itemize">
     Communication
     overhead
     for
     a
                                                                                         

                                                                                         
     GA
     is
     very
     light,
     so
     Java&#8217;s
     sometimes
     less
     than
     stellar
     performance
     is
     not
     really
     an
     issue.
     </li>
     <li class="itemize">
     Any
     Java
     program
     is
     already
     a
     MATLAB
     program.
     There&#8217;s
     no
     messing
     around
     with
     the
     external
     interface
     library.
     You
     just
     compile
     your
     Java
     and
     it
     acts
     just
     like
     any
                                                                                         

                                                                                         
     other
     MATLAB
     function.
     </li>
     <li class="itemize">
     Java
     is
     (more
     or
     less)
     platform-independent.
     I
     needed
     a
     parallel
     computing
     solution
     that
     worked
     transparently
     in
     a
     heterogeneous
     computing
     environment,
     with
     Linux,
     Windows,
     and
     MacIntosh
     machines
     distributed
     across
     the
     network,
     and
     this
     made
     a
     Java-based
     solution
     an
     attractive
     option.</li></ul>
<!--l. 3737--><p class="noindent" >This early system was very simple, but neither robust nor user-friendly. The user was required to use multiple
populations, and the parallel computing system was designed to send each population, via the RMI protocol, to a
                                                                                         

                                                                                         
separate core for processing. When done, RMI sent the results back to the Ferret console node for processing. This
approach was <span 
class="cmti-10">very </span>limited because without any load balancing, the rate of processing was dominated
by the slowest worker node that contributed to the calculation. Really, it was only useful when all
of the processing nodes were equally fast and under no other significant load. This early code was
also not very easy to use, had very little error recovery to deal with unresponsive (or crashed) nodes,
and had no facility to disconnect or add new nodes once the calculation had started. I only built this
rather fragile system for my own use to take advantage of a multi-core machine that I was using at the
time, and also because I was interested in RMI. Nevertheless, it served my purposes at the time rather
well.
<!--l. 3739--><p class="noindent" >I dropped the RMI approach in Ferret-2 because I was more interested in core GA development (specifically the
linkage-learning problem, as well as a few others) and Ferret was evolving rapidly. The development of my simple
RMI system simply did not keep pace with the rest of Ferret, and the package lost its parallel computing capabilities
for about the next four years.
<a 
 id="dx57-81005"></a>
<a 
 id="dx57-81006"></a>
<a 
 id="dx57-81007"></a>
<!--l. 3744--><p class="noindent" >Recently, I&#8217;ve brought back parallel computing to Ferret-4 using a much more robust file-system
based approach, and I have also ported the system to work with Locust. A similar approach is
employed by two commonly used (and free) parallel computing MATLAB toolboxes called
pMATLAB (http://www.ll.mit.edu/mission/isr/pMATLAB/pMATLAB.html) and MATLABMPI
(http://www.ll.mit.edu/mission/isr/MATLABmpi/MATLABmpi.html). However, the parallel computing
system is built in to Qubist and is not based on either of these packages, and no extra software is
required to run parallel jobs with Qubist. Building Qubist&#8217;s parallel code as a customized system
embedded in the code means that it could be built as a relatively simple, light-weight system with a user
interface specifically designed for Qubist. It does not require the generality of these other packages
because it only manages parallel computing for Ferret and Locust. This file system-based parallel
computing code performs very well due to the low communication overhead of GAs and particle swarm
optimizers.
<!--l. 3746--><p class="noindent" >Qubist&#8217;s new parallel computing system is analogous to a &#8216;feeding frenzy&#8217;: each node reads a work file that indicates
what parameter sets (drawn from the population) are remaining to evaluate, reserves a chunk of the remaining work,
and then it goes off to do its portion of the evaluation. When done, it writes information back to the work file to
indicate which solutions it evaluated, and the actual solutions are saved in a scratch directory. I liken this
system to a &#8216;feeding frenzy&#8217; because it&#8217;s completely asynchronous - worker nodes compete to reserve
work chunks on a &#8216;first come first serve&#8217; basis. Contrast this with the orderly RMI-based system that
I described above. The new system never sits waiting idle for a slow node. If there is no work left
that has not been reserved, then nodes that are finished jump in and start doing work that has been
reserved, but not completed. The first node to finish all of the work sends a message to the others to
indicate that the current set of solutions is fully evaluated, and that all other nodes should stop what
they&#8217;re doing and wait for the next batch of work. There is also a system in place that disconnects any
node that has become unresponsive, and sends a signal to the unresponsive node to shut down if it is
running.
<!--l. 3748--><p class="noindent" >The main challenge with this chaotic feeding frenzy approach is to very carefully control access to the scratch
directory where the results are being accumulated. This is done using a lock file as a semaphore: i.e. a single file that
indicates whether or not the scratch directory is currently being written to by another node. If the directory is
locked, then all other nodes must wait until the node doing the writing indicates that it is done. This can be tricky,
and I had plenty of problems with node lock-ups during development. These problems have all been solved, and the
                                                                                         

                                                                                         
current system is very robust.
<!--l. 3750--><p class="noindent" >Qubist&#8217;s parallel computing system is especially useful for problems with fitness functions that require more than a
few tenths of a second per evaluation (i.e. for a single parameter set). A thorough parameter search and
optimization may require many CPU-hours or even CPU-days of computation for such problems. This is not at all
uncommon for scientific modeling because the underlying mathematical systems are often very complex. Some of my
own applications in astrophysics require up to a CPU-month of computing, although a CPU-day or two is more
typical. I develop another code called GalAPAGOS (<span class="underline">Gal</span>axy <span class="underline">A</span>strophysical <span class="underline">P</span>arameter <span class="underline">A</span>cquisition by <span class="underline">G</span>enetic
<span class="underline">O</span>ptimization <span class="underline">S</span>oftware) at the University of Manitoba, which uses Ferret to fit astrophysical models to the
rotating neutral hydrogen disks present in spiral galaxies. Figure <a 
href="#x57-810081">6.1<!--tex4ht:ref: fig:parallelBench --></a> shows the results from a careful
benchmarking experiment of Ferret&#8217;s parallel computing system running GalAPAGOS models. The
code was run eight times, using one to eight cores on an eight core server. The experiment was done
a total of five times, corresponding to the five lines on the figure. The code ran for 100 generations
each time, which was not long enough for the code to converge, but was sufficient to obtain accurate
timing information. The left panel of the figure shows the results on a linear scale, and the right panel
shows the same data on a logarithmic scale. The dashed line on the right panel shows a -0.8 power law
for comparison. Note that a perfect parallelization scheme with no overhead would obey a -1 power
law.
<!--l. 3752--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         

                                                                                         
<a 
 id="x57-810081"></a>
                                                                                         

                                                                                         
<div class="center" 
>
<!--l. 3753--><p class="noindent" >

<!--l. 3754--><p class="noindent" ><img 
src="figures/Ferret/benchmark.png" alt="PIC"  
> <img 
src="figures/Ferret/benchmark2.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;6.1:  </span><span  
class="content">Results  of  a  benchmarking  experiment  of  Ferret&#8217;s  parallel  computing  system,  using  the
GalAPAGOS astrophysical modeling code as the fitness function. The code was run eight times, using one to
eight cores on an eight core server. The experiment was done a total of five times, corresponding to the five
lines on the figure. Both panels show the same data, on a linear scale (left) and a logarithmic scale (right).
The right panel shows a -0.8 power law for comparison.</span></div><!--tex4ht:label?: x57-810081 -->
                                                                                         

                                                                                         
<!--l. 3759--><p class="noindent" ></div><hr class="endfigure">
<!--l. 3761--><p class="noindent" >The parallel computing system is <span 
class="cmti-10">not </span>very useful for projects with fitness function that evaluate very quickly (i.e. an
entire Ferret generation or Locust time step finishes in a few seconds), because in such cases the optimizer&#8217;s internal
calculations become the computational bottleneck. These types of problems finish quickly without
parallelization in any case. If you are unsure about whether parallel computing is suitable for your problem,
just try it. <a 
 id="dx57-81009"></a><a 
 id="dx57-81010"></a> <a 
 id="dx57-81011"></a><a 
 id="dx57-81012"></a> You do not have to modify your code, although one tiny addition discussed in Section
<a 
href="QubistHTMLse40.html#x62-940006.4.4">6.4.4<!--tex4ht:ref: sec:isAbortEval --></a> can help. If you notice a speed-up, leave Ferret or Locust in parallel mode, or fall back to single
processor mode if not. Note that this can be done through a simple user interface, even while the code is
running!
                                                                                         

                                                                                         
<!--l. 3763--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse38.html" >next</a>] [<a 
href="QubistHTMLse37.html" >front</a>] [<a 
href="QubistHTMLch6.html#QubistHTMLse37.html" >up</a>] </p></div>
<!--l. 3763--><p class="noindent" ><a 
 id="tailQubistHTMLse37.html"></a>  
</body></html> 
