<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Introduction</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,frames,3 --> 
<meta name="src" content="QubistHTML.tex"> 
<meta name="date" content="2012-02-01 01:22:00"> 
<link rel="stylesheet" type="text/css" href="QubistHTML.css"> 
</head><body 
>
<!--l. 6817--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse84.html" >next</a>] [<a 
href="#tailQubistHTMLse83.html">tail</a>] [<a 
href="QubistHTMLch11.html#QubistHTMLse83.html" >up</a>] </p></div>
<h3 class="sectionHead"><span class="titlemark">11.1   </span> <a 
 id="x114-18400011.1"></a>Introduction</h3>
                                                                                         

                                                                                         
<a 
 id="dx114-184001"></a>
<a 
 id="dx114-184002"></a>
<!--l. 6822--><p class="noindent" >Locust is Qubist&#8217;s multi-objective particle swarm optimizer (PSO). It is much newer than Ferret and faster on many
problems, but perhaps less well-suited for the most difficult problems. Still, Locust is a very powerful code that I
regard as a front line optimizer of the Qubist package. It is an excellent alternative to Ferret and ideal for problems
of moderate to high difficulty. Locust shares many features with Ferret, including built-in parallel computing
capabilities (Chapter <a 
href="QubistHTMLch6.html#x56-800006">6<!--tex4ht:ref: ch:parallel --></a> and Section <a 
href="QubistHTMLse48.html#x73-1040008.5">8.5<!--tex4ht:ref: sec:par_parallel --></a>), analysis techniques (Section <a 
href="QubistHTMLse25.html#x42-630004.15">4.15<!--tex4ht:ref: sec:analysis --></a>), crash recovery/resume features (Sections
<a 
href="QubistHTMLse26.html#x43-650004.16.1">4.16.1<!--tex4ht:ref: sec:crash --></a> and <a 
href="QubistHTMLse27.html#x45-690004.17">4.17<!--tex4ht:ref: sec:resumeRun --></a>), History files (Section <a 
href="QubistHTMLse26.html#x43-680004.16.4">4.16.4<!--tex4ht:ref: sec:History_files --></a>), a visualization interface (Section <a 
href="QubistHTMLse32.html#x51-750005.2">5.2<!--tex4ht:ref: sec:binaryResults --></a>), and the ability to call
SAMOSA, Anvil, SemiGloSS, and fminsearch as polishers (Sections <a 
href="QubistHTMLse26.html#x43-640004.16">4.16<!--tex4ht:ref: sec:polish --></a> and <a 
href="QubistHTMLse61.html#x89-1270008.18">8.18<!--tex4ht:ref: sec:par_polish --></a>). In some ways, Locust <span 
class="cmti-10">is </span>Ferret,
since I borrowed many of its features directly from Ferret during development. Many of Locust&#8217;s features will
therefore look familiar if you have already tried Ferret because the two optimizers share a great deal of
code.
<!--l. 6824--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">11.1.1   </span> <a 
 id="x114-18500011.1.1"></a>History</h4>
<a 
 id="dx114-185001"></a>
<a 
 id="dx114-185002"></a>
<!--l. 6829--><p class="noindent" >I started working (rather casually) on PSOs during spring 2007, and was immediately struck by the collective
behaviour that emerged from the dynamics of rather simple interacting particles. I was also quite thrilled to
see that even my first simple PSO worked quite nicely, albeit on fairly simple test problems. I have
always enjoyed dynamics as an astronomer and a physicist, and I believe that my academic background
gave me some insight into how this fascinating new tool worked. Locust developed consistently for the
next two years, even while I put the bulk of my effort into perfecting Ferret. It became a reasonably
powerful multi-objective code during this time, and inherited Ferret&#8217;s interfaces for visualization and
polishing.
<!--l. 6831--><p class="noindent" >Between 2007 and spring 2009, Locust&#8217;s development went down one road that I came to regret. As I commented at
the top of Chapter <a 
href="QubistHTMLch10.html#x103-15600010">10<!--tex4ht:ref: ch:Anvil --></a>, my optimizers often start to look like genetic algorithms if I work on them for long enough.
This is quite natural - I&#8217;ve been developing Ferret almost obsessively for about seven years at the time of this
writing. I think about optimization most naturally in terms of evolutionary computing, and I&#8217;ve learned many
genetic algorithm tricks during this time. The paradigm of evolution provides an especially rich and flexible
framework for optimization, and this flexibility admits the possibility of novel hybridization schemes with other
types of optimization methods.
<!--l. 6833--><p class="noindent" >Sometimes, hybridization with a genetic algorithm is successful, as is the case of Anvil. Sometimes it&#8217;s not so useful,
as was the case of Locust. Locust-1 had a solid foundation in particle swarm dynamics, but this was mixed with
genetic algorithm components, and frankly I did not really understand how the evolutionary parts interacted with
the particle swarm dynamics. When I first sat down to write this chapter in July 2009, I spent the better part of a
month testing and critiquing Locust and trying to sort out the useful parts from the junk. In the end, I determined
that the particle swarm parts were well designed and effective, but <span 
class="cmti-10">none </span>of the genetic algorithm components were
helping at all. I removed all of the genetic algorithm parts, which caused the code to shrink by about a third.
During my testing, I also made some very significant enhancements to the swarm dynamics, which
turned Locust into a much more powerful tool than previous versions. This encouraged me to add
Ferret&#8217;s crash recovery and parallel computing features, and once I had connected everything, the newly
streamlined Locust warranted an updated version number and a more prominent role in the Qubist package.
                                                                                         

                                                                                         
Locust-2 emerged as an exciting new optimizer suitable for use as the primary optimizer for many
problems.
<a 
 id="dx114-185003"></a>
<!--l. 6836--><p class="noindent" >Locust-2 has already been through quite a lot of testing, and its performance characteristics complement Ferret
perfectly. Locust can do almost all of the test problems that come with Qubist, except for the ones that focus
heavily on linkage-learning. Generally, it finds solutions much more quickly than Ferret, although it does not map
extended optimal solutions quite as thoroughly. The same conclusion seems to hold true for two difficult &#8216;real-world&#8217;
problems in astrophysics that graduate students at the University of Manitoba have tried using both Ferret and
Locust. You should definitely try Locust if you care more about speed than mapping an extended optimal or
trade-off surface in great detail!
<a 
 id="dx114-185004"></a>
<a 
 id="dx114-185005"></a>
<!--l. 6842--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">11.1.2   </span> <a 
 id="x114-18600011.1.2"></a>PSO Basics</h4>
<a 
 id="dx114-186001"></a>
<a 
 id="dx114-186002"></a>
<!--l. 6846--><p class="noindent" >There are excellent books on PSOs (e.g. <a 
href="QubistHTMLli1.html#Xeberhart01">Eberhart</a>&#x00A0;[<a 
href="QubistHTMLli1.html#Xeberhart01">2001</a>]) and additional resources can be found readily in
journals and on the web. I will only briefly outline the basic ideas of PSOs here. PSOs are similar to
genetic algorithms in that they sample many points in the search space simultaneously. Where a genetic
algorithm has a <span 
class="cmti-10">population </span>of <span 
class="cmti-10">individuals </span>exploring the search space at any given <span 
class="cmti-10">generation</span>, a PSO
has a <span 
class="cmti-10">swarm </span>of <span 
class="cmti-10">particles </span>moving through the search space at any given <span 
class="cmti-10">time step</span>. The dynamics of
a simple PSO are surprisingly simple. Each particle in the swarm is simultaneously attracted to its
own &#8216;personal best&#8217; solution - the best solution that the particle has personally seen - and the &#8216;global
best&#8217; solution - the best solution that the entire swarm has ever seen. The law of attraction follows
a simple spring law: <span 
class="cmmi-10">F </span><span 
class="cmsy-10">&#x221D;|</span>&#x0394;<span 
class="cmmi-10">x</span><span 
class="cmsy-10">|</span>, where <span 
class="cmsy-10">|</span>&#x0394;<span 
class="cmmi-10">x</span><span 
class="cmsy-10">| </span>is the distance between a given particle and either the
personal best solution <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">p</span></sub> or the global best <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">g</span></sub>. Assuming that the force and velocity are approximately
constant over a time step, the new velocity and position of particle <span 
class="cmmi-10">i </span>after a time step &#x0394;<span 
class="cmmi-10">t </span>are given by
<div class="eqnarray">
<center class="math-display" >
<img 
src="QubistHTML126x.png" alt="vi(t+ &#x0394;t)  =  vi(t) + [cp&#x03BE;p(xp - xi)+ cg&#x03BE;g(xg - xi)]&#x0394;t
xi(t+ &#x0394;t)  =  xi(t)+ vi(t)&#x0394;t,                                     (11.1)
" class="math-display" ><a 
 id="x114-186003r11.1"></a></center>
</div>where <span 
class="cmmi-10">c</span><sub><span 
class="cmmi-7">p</span></sub> and <span 
class="cmmi-10">c</span><sub><span 
class="cmmi-7">g</span></sub> play the role of spring constants for the personal and global best solutions respectively. Some
                                                                                         

                                                                                         
randomness is injected via the uniform random variables <span 
class="cmmi-10">&#x03BE;</span><sub><span 
class="cmmi-7">p</span></sub> and <span 
class="cmmi-10">&#x03BE;</span><sub><span 
class="cmmi-7">g</span></sub>, which are typically drawn from the range 0 to 1.
The stochastic terms play a role similar to the mutation operator in a genetic algorithm; they add
randomness to the search, which helps the particles to explore previously unexplored parts of the parameter
space.
<!--l. 6854--><p class="noindent" >Equations <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a> amount to a simple Euler integration scheme for a dynamical system of equations that move each
particle every time step. The roles of the personal and global best solutions are clear; the personal best solution
represents a particle&#8217;s memory of the best region of parameter space that it has seen, and the global best solution
represents the entire swarm&#8217;s collective memory. In effect, the global best solution ties all of the particles together to
encourage collective behaviour.
<a 
 id="dx114-186004"></a>
<a 
 id="dx114-186005"></a>
<a 
 id="dx114-186006"></a>
<!--l. 6859--><p class="noindent" >Particle swarm optimization is a young and rapidly changing field of research that still has many open questions,
which are discussed in a recent review by <a 
href="QubistHTMLli1.html#Xpoli">Poli, Kennedy &amp; Blackwell</a>&#x00A0;[<a 
href="QubistHTMLli1.html#Xpoli">2007</a>] in the inaugural edition of <span 
class="cmti-10">Swarm</span>
<span 
class="cmti-10">Intelligence</span>. There are different methods to initialize the swarm velocities and deal with particles that leave the
boundaries of the search. Equation <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a> is perhaps the simplest set of swarm equations, but there are also many
different implementations possible, which strive to balance thorough exploration of the parameter space against the
need to exploit high performance regions when they are found. Most PSO implementations include a damping term
in equations <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a>, which decreases the velocity magnitude in a time <span 
class="cmmi-10">t</span><sub><span 
class="cmmi-7">damp</span></sub> to help the swarm settle down as
it zeros in on the optimal region. This damping term is in some ways analogous to the cooling of a
simulated annealing code, although there is no analogue in a genetic algorithm. It is also common to limit
the velocity to prevent runaway growth. Locust uses damping, but does not require a velocity limit.
Locust uses an exact solution to the swarm equations, rather than the Euler integration scheme in
equation <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a>, as discussed in Section <a 
href="#x114-18700011.1.3">11.1.3<!--tex4ht:ref: sec:LocustEnhancedPSO --></a>. As a multi-objective optimizer, it also requires some
non-standard techniques designed to fill out the Pareto surface, which are also discussed in Section
<a 
href="#x114-18700011.1.3">11.1.3<!--tex4ht:ref: sec:LocustEnhancedPSO --></a>.
<!--l. 6861--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">11.1.3   </span> <a 
 id="x114-18700011.1.3"></a>Locust as an Enhanced Multi-Objective PSO</h4>
<a 
 id="dx114-187001"></a>
<a 
 id="dx114-187002"></a>
<a 
 id="dx114-187003"></a>
<!--l. 6867--><p class="noindent" >In physics, a simple harmonic oscillator (SHO) potential is a potential energy function of the form
<table 
class="equation"><tr><td><a 
 id="x114-187004r2"></a>
<center class="math-display" >
<img 
src="QubistHTML127x.png" alt="     1
U =  -k|x|2,
     2
" class="math-display" ></center></td><td class="equation-label">(11.2)</td></tr></table>
<!--l. 6871--><p class="nopar" >
where <span 
class="cmmi-10">k &#x003E; </span>0 is a spring constant and <span 
class="cmsy-10">|</span><span 
class="cmmi-10">x</span><span 
class="cmsy-10">| </span>is the distance from the centre of attraction at the origin. It is easily shown
that this potential results in forces that are consistent with Hooke&#8217;s law for springs <span 
class="cmmi-10">F </span>= <span 
class="cmsy-10">-</span><span 
class="cmmi-10">kx</span>, and that the exact
solution for a particle moving in a SHO potential (in a space of arbitrary dimensionality greater than 2) is a closed
orbit within a plane. The equations governing this motion can be solved exactly to give position and velocity as
a function of time, and it is easy to generalize this result to the case that there are two centres of
attraction rather than one. Locust does not really use the approximate SHO solution given by equation
<a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a>. Rather, it solves the exact analytical trajectories traced by equation <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a> in the limit &#x0394;<span 
class="cmmi-10">t </span><span 
class="cmsy-10">&#x2192; </span>0,
with a damping term included. Solving these equations exactly requires some effort, but my numerical
experiments show that the exact solution results in more stable and reliable PSO. I believe that this is
because the exact solution eliminates the build-up of errors in the orbits, which would result from
applying equation <a 
href="#x114-186003r11.1">11.1<!--tex4ht:ref: eq:PSO --></a> directly with a finite &#x0394;<span 
class="cmmi-10">t</span>. The exact solution is of course slightly more costly to
evaluate than the Euler approximation, but this extra computational expense is insignificant for any
realistic problem, where the computational time is normally dominated by the evaluation of the fitness
function.
<a 
 id="dx114-187005"></a>
<a 
 id="dx114-187006"></a>
<a 
 id="dx114-187007"></a>
<a 
 id="dx114-187008"></a>
<a 
 id="dx114-187009"></a>
<a 
 id="dx114-187010"></a>
<a 
 id="dx114-187011"></a>
<a 
 id="dx114-187012"></a>
<a 
 id="dx114-187013"></a>
<!--l. 6883--><p class="noindent" >Choosing <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">p</span></sub> is straightforward because it represents the personal best solution (or <span 
class="cmti-10">pbest </span>solution) that any particle
has encountered in it&#8217;s travels. Thus, one simply keeps track of the position of the lowest value of the fitness
function <span 
class="cmmi-10">F</span>(<span 
class="cmmi-10">x</span>), following Ferret&#8217;s convention that low values of <span 
class="cmmi-10">F </span>correspond to more desirable solutions. The most
common particle swarm implementation is the version discussed in Section <a 
href="#x114-18600011.1.2">11.1.2<!--tex4ht:ref: sec:PSO_basics --></a>, where the global best
solution (or <span 
class="cmti-10">gbest </span>solution) <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">g</span></sub> is evaluated over the entire swarm. This swarm topology can be thought
of as a fully connected graph, where the entire swarm of particles &#8216;talk&#8217; to each other via the <span 
class="cmti-10">gbest</span>
solution. It is easy to imagine other swarm topologies, where the network of communication between
swarm members is less densely connected, so that each particle only talks to a few other particles in its
neighbourhood. In this case, different particles may have different <span 
class="cmti-10">gbest </span>solutions, depending on the best
solutions that have been discovered by its neighbours. This scenario is referred to as a static <span 
class="cmti-10">lbest </span>(for
&#8216;local best&#8217;) topology when the network connecting particles is static such that it does not change
throughout the run. Swarms based on sparsely connected networks can be thought of as being divided into
sub-swarms, where each sub-swarm shares a common <span 
class="cmti-10">gbest </span>solution. Such a topology is able to avoid local
minima better because the sub-swarms essentially explore the space in parallel. On the other hand, the
fully connected <span 
class="cmti-10">gbest </span>topology is best for exploiting a single isolated solution late in a run, because it
focusses the efforts of the entire swarm on the region of parameter space in the vicinity of the <span 
class="cmti-10">gbest</span>
solution.
<a 
 id="dx114-187014"></a>
<a 
 id="dx114-187015"></a>
                                                                                         

                                                                                         
<a 
 id="dx114-187016"></a>
<!--l. 6888--><p class="noindent" >The standard <span 
class="cmti-10">gbest </span>approach would not make much sense for a multi-objective particle swarm algorithm like Locust,
which aims to populate a spatially extended Pareto front with a set of optimal solutions that are equally good.
Extended solutions sets are also possible when a fuzzy tolerance is specified for a single objective problem, which
often represents the <span 
class="cmmi-10">&#x03C7;</span><sup><span 
class="cmr-7">2</span></sup> error tolerance of a data-modeling problems. In such cases, a single global
best solution would put too much emphasis on a single point within the set of optimal solutions, and
the mapping of the optimal set would be extremely poor. Locust uses a dynamic swarm topology
that is similar to the <span 
class="cmti-10">lbest </span>topology, except that the proximity of particles in Euclidean space is used
to define the initial neighbourhoods, and these neighbourhoods evolve dynamically throughout the
run. Neighbourhoods merge and divide as required to map out the extended structure of the optimal
set.
<!--l. 6890--><p class="noindent" >The transition from a fully connected <span 
class="cmti-10">gbest </span>algorithm to an <span 
class="cmti-10">lbest</span>-style algorithm with a dynamic topology
is the main enhancement that resulted in the development of Locust-2 during the summer of 2009.
The resulting code is much more powerful and versatile than its predecessor, and works equally well
on single and multi-objective problems. The underlying dynamic swarm topology is quite different
from other topologies discussed in the literature, and has the benefit that it essentially self-optimizes.
A large number of neighbourhoods will be preserved to map a spatially extended solution set, but
the swarm topology will correctly collapse to a single neighbourhood late in a run if only a single
solution exists. I view this technique as the optimal balance between exploration and exploitation: the
parallel action of many sub-swarms evade local minima early in the run for all problems, and are
retained to the end when the focus is on mapping an extended solution set, but swarms reduce to the
maximally exploiting <span 
class="cmti-10">gbest </span>algorithm late in the run for problems where only a single best solution
exists.
<a 
 id="dx114-187017"></a>
<a 
 id="dx114-187018"></a>
<a 
 id="dx114-187019"></a>
                                                                                         

                                                                                         
<!--l. 6896--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse84.html" >next</a>] [<a 
href="QubistHTMLse83.html" >front</a>] [<a 
href="QubistHTMLch11.html#QubistHTMLse83.html" >up</a>] </p></div>
<!--l. 6896--><p class="noindent" ><a 
 id="tailQubistHTMLse83.html"></a>  
</body></html> 
