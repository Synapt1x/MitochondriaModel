<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Multi-Objective Optimization</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,frames,3 --> 
<meta name="src" content="QubistHTML.tex"> 
<meta name="date" content="2012-02-01 01:22:00"> 
<link rel="stylesheet" type="text/css" href="QubistHTML.css"> 
</head><body 
>
                                                                                         

                                                                                         
<!--l. 337--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse2.html" >next</a>] [<a 
href="#tailQubistHTMLse1.html">tail</a>] [<a 
href="QubistHTMLch2.html#QubistHTMLse1.html" >up</a>] </p></div>
<h3 class="sectionHead"><span class="titlemark">2.1   </span> <a 
 id="x7-70002.1"></a>Multi-Objective Optimization</h3>
<a 
 id="dx7-7001"></a>
<a 
 id="dx7-7002"></a>
<!--l. 342--><p class="noindent" >Multi-objective optimization can be a tricky concept the first time you encounter it, especially if you
are used to working with single-objective optimizers. There are many real optimization problems in
science, engineering, finance and other fields where the design goals are characterized by multiple
objectives, but I like to use a very simple (albeit somewhat contrived) example to illustrate the key
point. Imagine a factory manufacturing widgets, where the design of a widget is controlled by some
set of parameters, and the goal is to find a widget design that simultaneously maximizes quality and
minimizes production cost. Intuitively, higher quality widgets are usually more costly to make than
lower quality widgets. What then is the optimal widget design that the factory should ultimately
produce?
<a 
 id="dx7-7003"></a>
<a 
 id="dx7-7004"></a>
<!--l. 346--><p class="noindent" >The correct answer is that there is no single optimal widget design. Rather, there is an optimal family of widgets
defined by the property that you cannot improve the quality of any widget in the optimal set without
simultaneously increasing its cost. Likewise, it is not possible to make any optimal widget cheaper without also
degrading its quality. If you search harder and discover a new design that is simultaneously better
and cheaper than some of the other designs in the current optimal set, then this new solution would
be truly superior, and it would effectively remove all inferior solutions from the family of optimal
solutions. Eventually you will discover a curve containing feasible solutions that you can&#8217;t improve
upon, which represents the trade-offs between the design objectives. Trade-off surfaces are discussed
commonly in engineering, where the goal is often to optimize a design subject to multiple criteria and
constraints.
<a 
 id="dx7-7005"></a>
<a 
 id="dx7-7006"></a>
<!--l. 350--><p class="noindent" >The trade-off surface is also referred to as the Pareto-optimal set, and is easily generalized to an arbitrary number of
objectives. The Pareto-optimal set can be defined as the set of solutions to a multi-objective problem such that no
objective can be improved without degrading at least one other. This definition can be made more mathematical,
but from a practical standpoint, little is gained by doing so.
<a 
 id="dx7-7007"></a>
<!--l. 353--><p class="noindent" >A multi-objective optimizer has a very difficult task, since it must search for solutions on the trade-off surface and
then map the surface as completely as possible by populating it with points. Note that this is much more
complicated than the goal of a standard optimizer, which usually seeks only a single optimal solution. All of the
Qubist optimizers are multi-objective, but Ferret is best at mapping trade-off surfaces. Unfortunately, adding
multi-objective capabilities to a genetic algorithm increases the complexity of its implementation substantially,
although not necessarily its use. However, a good multi-objective GA can solve problems that you simply can&#8217;t do
with a single-objective optimizer. Furthermore, since a trade-off surface represents the necessary compromises
between equally good feasible solutions that are all optimal, the user of such a code is presented with many
alternatives solutions. Inevitably, the user is bound to prefer some of these solutions over others, even though all are
equally good from a mathematical point of view, and this may in turn help the user to refine the problem&#8217;s
objectives.
<a 
 id="dx7-7008"></a>
<a 
 id="dx7-7009"></a>
                                                                                         

                                                                                         
<!--l. 357--><p class="noindent" >The core feature of a multi-objective optimizer is its ability to spread solutions out over an optimal region of
parameter space, for problems that do not admit a single optimal solution. This is absolutely required for
multi-objective problems, but in practice, it is also often useful for a common type of data-modeling problem, where
the data contain significant noise or uncertainty. Let me illustrate with the common problem of modeling data
with noise, where you typically want to minimize the reduced chi-squared statistic over the space of <span 
class="cmmi-10">n</span>
model parameters: <span 
class="cmmi-10">&#x03C7;</span><sub><span 
class="cmmi-7">reduced</span></sub><sup><span 
class="cmr-7">2</span></sup>(<span 
class="cmmi-10">P</span><sub><span 
class="cmr-7">1</span></sub><span 
class="cmmi-10">,P</span><sub><span 
class="cmr-7">2</span></sub><span 
class="cmmi-10">,</span><span 
class="cmmi-10">&#x2026;</span><span 
class="cmmi-10">,P</span><sub><span 
class="cmmi-7">n</span></sub>). In such problems, all models within about 1-sigma of the
minimum value (<span 
class="cmmi-10">&#x03C7;</span><sub><span 
class="cmmi-7">reduced</span></sub><sup><span 
class="cmr-7">2</span></sup> <span 
class="cmmi-10">&#x003C; &#x03C7;</span><sub><span 
class="cmmi-7">min,reduced</span></sub><sup><span 
class="cmr-7">2</span></sup> + 1) are virtually indistinguishable because their differences are
buried in the noise. In a sense, this amounts to a &#8216;fuzzy&#8217; optimization problem, where there is usually
a single solution that is truly optimal, but also a finite-sized region that is nearly indistinguishable
within the errors of the data. Mapping this region provides an intuitive and automatic method to
determine all parameter values, their uncertainties, and the sensitivity of the objective function to each
parameter.
<a 
 id="dx7-7010"></a>
<a 
 id="dx7-7011"></a>
<a 
 id="dx7-7012"></a>
<a 
 id="dx7-7013"></a>
<a 
 id="dx7-7014"></a>
<!--l. 364--><p class="noindent" >In simple cases, the optimal region of a fuzzy single-objective problem forms a multi-dimensional ball surrounding
the &#8216;best&#8217; solution, but the Qubist optimizers sometimes discover more complex geometric structures in real-world
problems. When this happens, it can tell you something important about the degeneracies of your model. If such a
fuzzy optimal set contains models that range widely in their parameters, but &#8216;look&#8217; similar to the fitness function in
that they all produce essentially the same fitness value, then this is the symptom of mathematical degeneracy -
two or more parameters playing off against each other in a way that makes their independent values
<span 
class="cmti-10">unknowable </span>from the existing data alone. Chapter <a 
href="QubistHTMLch5.html#x49-730005">5<!--tex4ht:ref: ch:visualization --></a> shows an example of how Ferret can be used to
discover degeneracy in a model and infer its mathematical structure. This type of problem is where
visualization of the optimal set becomes critical because mathematical degeneracy <span 
class="cmti-10">looks </span>like a long
curve of solutions snaking through the parameter space, a surface populated with points, or some
higher-dimensional hypersurface. The point is that the signature of model degeneracy is usually quite
obvious <span 
class="cmti-10">when you see it</span>. All of the Qubist optimizers can be used for this sort of analysis, although
Ferret and Locust do it most thoroughly. They are both very good at mapping these structures, and
visualization tools are directly accessible from the Ferret and Locust interfaces to help you to see
them.
<a 
 id="dx7-7015"></a>
<a 
 id="dx7-7016"></a>
<a 
 id="dx7-7017"></a>
<a 
 id="dx7-7018"></a>
<a 
 id="dx7-7019"></a>
<!--l. 371--><p class="noindent" >All of the core optimizers in the Qubist package are designed for multi-objective optimization and parameter space
mapping. Ferret has the longest development history of these optimizers, and its multi-objective capabilities have
been a core feature of the algorithm from the start. These multi-objective capabilities have been well-tested on a
variety of test problems and difficult problems in research, and are regarded as robust and extremely reliable. Locust
is one of few multi-objective particle swarm optimizers in existence, and its multi-objective feature is based almost
entirely on robust code borrowed from Ferret. The same is true of Anvil, whose multi-objective capabilities also
borrow heavily from Ferret. SAMOSA has a different goal. Rather than fully mapping the optimal set, SAMOSA
aims to <span 
class="cmti-10">either </span>map the trade-off surface sparsely with a few high quality solutions, <span 
class="cmti-10">or </span>zero in on the
nearest part of the trade-off surface to an initial guess, depending on how it is configured. This second
configuration makes it extremely useful as a solution polisher for Ferret and Locust, but it is of limited
                                                                                         

                                                                                         
use on problems that require a thoroughly mapped optimal set of solutions. All Qubist optimizers
share a common interface to user-defined initialization, fitness, and custom graphics functions, and all
can understand Ferret&#8217;s setup file format. This makes it trivial to swap optimizers for comparison
purposes.
<a 
 id="dx7-7020"></a>
<a 
 id="dx7-7021"></a>
<a 
 id="dx7-7022"></a>
<!--l. 376--><p class="noindent" >One of Qubist&#8217;s overall goals is to go beyond the limitations of a typical optimization package by offering nearly
autonomous knowledge discovery tools, which can illuminate interesting features of a problem&#8217;s parameter space and
help direct the human user towards an improved understanding of the problem. Qubist&#8217;s multi-objective and
parameter space-mapping capabilities, in conjunction with good visualization tools, are the first and simplest
features that illustrate this discovery capability. Ferret also contains other advanced features designed to elucidate
the mathematical structure of a problem, which will be outlined in Sections <a 
href="QubistHTMLse2.html#x8-140002.2.6">2.2.6<!--tex4ht:ref: sec:CPD --></a> to <a 
href="QubistHTMLse2.html#x8-160002.2.8">2.2.8<!--tex4ht:ref: sec:strategy --></a>. Some of
these capabilities carry over to the other Qubist optimizers, which will be discussed in subsequent
chapters.
<a 
 id="dx7-7023"></a>
                                                                                         

                                                                                         
<!--l. 380--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse2.html" >next</a>] [<a 
href="QubistHTMLse1.html" >front</a>] [<a 
href="QubistHTMLch2.html#QubistHTMLse1.html" >up</a>] </p></div>
<!--l. 380--><p class="noindent" ><a 
 id="tailQubistHTMLse1.html"></a>  
</body></html> 
