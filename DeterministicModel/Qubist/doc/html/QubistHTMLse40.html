<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Common Parallelization Gotchas</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,frames,3 --> 
<meta name="src" content="QubistHTML.tex"> 
<meta name="date" content="2012-02-01 01:22:00"> 
<link rel="stylesheet" type="text/css" href="QubistHTML.css"> 
</head><body 
>
<!--l. 3849--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse39.html" >prev</a>] [<a 
href="QubistHTMLse39.html#tailQubistHTMLse39.html" >prev-tail</a>] [<a 
href="#tailQubistHTMLse40.html">tail</a>] [<a 
href="QubistHTMLch6.html#QubistHTMLse40.html" >up</a>] </p></div>
<h3 class="sectionHead"><span class="titlemark">6.4   </span> <a 
 id="x62-900006.4"></a>Common Parallelization Gotchas</h3>
<!--l. 3851--><p class="noindent" >There are a couple of problems that come up occasionally with parallel runs. You need to be aware of these issues
you plan to run in parallel mode, especially if you are a Linux user, or if your project requires a lot of
memory.
<!--l. 3853--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">6.4.1   </span> <a 
 id="x62-910006.4.1"></a>Use a Local Disk When Possible</h4>
<!--l. 3855--><p class="noindent" >Reading and writing files on a local disk is normally <span 
class="cmti-10">much </span>faster than accessing files on a shared disk over a
network. Qubist&#8217;s file system based parallelization method will therefore perform best if your run&#8217;s data directory is
on a local disk connected to the machine running the Ferret console. If your run involves worker nodes running on
multiple machines, then you can minimize the parallelization communication overhead by placing your data
directory on a disk connected to the machine hosting the most worker nodes, and also running the Ferret console
from the same machine.
<!--l. 3857--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">6.4.2   </span> <a 
 id="x62-920006.4.2"></a>&#8216;Nicing&#8217; Down Runs</h4>
<a 
 id="dx62-92001"></a>
<!--l. 3860--><p class="noindent" >The Linux and MacIntosh operating systems allow users to &#8216;nice down&#8217; runs so that other jobs take priority on the
CPU. This is especially useful if other users are also trying to use the machines that are contributing to your parallel
calculation. In this case, you should be aware that all nodes that you start using the node manager will
take on the same priority as the node that you used to start the MATLAB process running the node
manager.  You should never include a &#8216;nice&#8217; command in the node manager&#8217;s command line. For example
&#8216;nice +19 matlab&#8217; won&#8217;t work. If you want to nice down your nodes, nice down the MATLAB process
running the node manager before you start nodes, or &#8216;renice&#8217; them from the Linux command line
afterward.
<!--l. 3862--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">6.4.3   </span> <a 
 id="x62-930006.4.3"></a>Memory Problems</h4>
<a 
 id="dx62-93001"></a>
                                                                                         

                                                                                         
<!--l. 3865--><p class="noindent" >If your project requires a lot of memory, or your machine is very memory deficient, then you should be aware that
nodes do not share memory,  so your memory requirements increase in proportion to the number of nodes. This is
unfortunate, but the problem is that every node runs in a separate MATLAB process, and I&#8217;m not aware of any
technique that allows multiple MATLAB processes to share memory. If you have this problem, you will probably
notice one of the following behaviours:
     <ul class="itemize1">
     <li class="itemize">
     Nodes
     take
     a
     very
     long
     time
     to
     start,
     or
     may
     never
     start.
     </li>
     <li class="itemize">
     Ferret
     or
     Locust
     slows
     right
     down.
     Your
     entire
     system
     may
     respond
     poorly,
     and
     you
     may
     even
     hear
     your
     disk
     drive
     making
     a
     lot
     of
                                                                                         

                                                                                         
     noise.
     This
     is
     symptomatic
     of
     running
     out
     of
     memory,
     and
     MATLAB
     trying
     to
     continue
     by
     using
     the
     swap
     file.
     This
     is
     not
     good,
     and
     you&#8217;d
     might
     as
     well
     stop
     the
     run
     because
     progress
     will
     be
     very
     slow.</li></ul>
<!--l. 3870--><p class="noindent" >To remedy this situation you can try to decrease your project&#8217;s memory usage, install more memory, or distribute
your run over multiple machines.
<!--l. 3872--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">6.4.4   </span> <a 
 id="x62-940006.4.4"></a>The &#8216;isAbortEval&#8217; Directive</h4>
<a 
 id="dx62-94001"></a>
<a 
 id="dx62-94002"></a>
                                                                                         

                                                                                         
<a 
 id="dx62-94003"></a>
<a 
 id="dx62-94004"></a>
<!--l. 3879--><p class="noindent" >Qubist&#8217;s parallel computing system works by assigning work chunks to worker nodes, and assembling the set of
solutions returned by the workers as they finish. Workers are never allowed to sit idle when work still needs to be
done; if a worker finished early, it is assigned a new work chunk, that may have also been assigned to a slower
worker that has not yet finished. Therefore, it is a good idea to halt any remaining evaluations that worker nodes
might still be executing, once Ferret or Locust has received the results from all of the fitness evaluations
requested.
<!--l. 3881--><p class="noindent" >This is done by monitoring for the &#8216;abortEval&#8217; signal, and placing a break point in the fitness function that is
triggered if <span 
class="cmtt-10">isAbortEval(extPar.status) </span>returns <span 
class="cmmi-10">true</span>:
<!--l. 3896--><p class="noindent" ><span 
class="colorbox" id="colorbox62"> <div class="minipage"><div class="BVerbatimInput"><span 
class="cmtt-10">function</span><span 
class="cmtt-10">&#x00A0;[F,auxOutput,saveData,XMod]=fitness(X,extPar)</span><br /><span 
class="cmtt-10">%</span><span 
class="cmtt-10">&#x00A0;Qubist</span><span 
class="cmtt-10">&#x00A0;demo</span><span 
class="cmtt-10">&#x00A0;fitness</span><span 
class="cmtt-10">&#x00A0;function.</span><br /><br /><span 
class="cmtt-10">NIndiv=size(X,2);</span><br /><span 
class="cmtt-10">for</span><span 
class="cmtt-10">&#x00A0;i=NIndiv:-1:1</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;if</span><span 
class="cmtt-10">&#x00A0;isAbortEval(extPar.status)</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;F=[];</span><span 
class="cmtt-10">&#x00A0;auxOutput={};</span><span 
class="cmtt-10">&#x00A0;saveData={};</span><span 
class="cmtt-10">&#x00A0;XMod=[];</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;break</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;end</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;[F(i),auxOutput{i},saveData{i},XMod(:.i)]=calcFitness(X(:,i),extPar);</span><br /><span 
class="cmtt-10">end</span></div>
</div></span>
<a 
 id="dx62-94016"></a>
<a 
 id="dx62-94017"></a>
<a 
 id="dx62-94018"></a>
<a 
 id="dx62-94019"></a>
<!--l. 3907--><p class="noindent" >If <span 
class="cmtt-10">isAbortEval(extPar.status) </span>returns <span 
class="cmmi-10">true</span>, then this means that Ferret or Locust no longer needs the remaining
fitness values that are still being computed, because another worker node finished evaluating them first. Therefore,
you should just return empty variables of the appropriate type for <span 
class="cmmi-10">F</span>, <span 
class="cmmi-10">auxOutput</span>, <span 
class="cmmi-10">saveData</span>, and <span 
class="cmmi-10">XMod</span>. Of course,
you can omit any that your fitness function does not use.
<a 
 id="dx62-94020"></a>
<a 
 id="dx62-94021"></a>
<a 
 id="dx62-94022"></a>
                                                                                         

                                                                                         
<!--l. 3914--><div class="crosslinks"><p class="noindent">[<a 
href="QubistHTMLse39.html" >prev</a>] [<a 
href="QubistHTMLse39.html#tailQubistHTMLse39.html" >prev-tail</a>] [<a 
href="QubistHTMLse40.html" >front</a>] [<a 
href="QubistHTMLch6.html#QubistHTMLse40.html" >up</a>] </p></div>
<!--l. 3914--><p class="noindent" ><a 
 id="tailQubistHTMLse40.html"></a>  
</body></html> 
